---
typora-root-url: ..\..
---

# 并发实战学习

### 一、可见性、原子性和有序性问题：并发编程Bug的源头

1. ##### 为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为：

   - CPU 增加了缓存，以均衡与内存的速度差异；

   - 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异

   - 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用

     

2. ##### 缓存导致的可见性问题

   在单核时代，所有的线程都是在一颗 CPU 上执行。所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如：线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值。

   ![cpu缓存与内存的关系](/Picture/Java并发/极客时间-Java并发编程实战/CPU缓存与内存的关系.png)

   多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。

   ![多核CPU的缓存与内存关系图](/Picture/Java并发/极客时间-Java并发编程实战/多核CPU的缓存与内存关系图.png)

   `public class Test {
     private long count = 0;
     private void add10K() {
       int idx = 0;
       while(idx++ < 10000) {
         count += 1;
       }
     }
     public static long calc() {
       final Test test = new Test();
       // 创建两个线程，执行add()操作
       Thread th1 = new Thread(()->{
         test.add10K();
       });
       Thread th2 = new Thread(()->{
         test.add10K();
       });
       // 启动两个线程
       th1.start();
       th2.start();
       // 等待两个子线程执行结束
       th1.join();
       th2.join();
       return count;
     }
   }`

   该代码块两个线程会可能会在两个cpu上执行，这样每个cpu都有自己的缓存，cpu的缓存不及时和内存进行同步所以count会小于20000

   

3. ##### 线程切换带来的原子性问题

   现代的操作系统都基于更轻量的线程来调度，我们提到的“任务切换”都是指“线程切换”。任务切换也是并发编程里诡异 Bug 的源头之一。高级语言里一条语句往往需要多条 CPU 指令完成，count += 1，至少需要三条 CPU 指令。

   - 首先，需要把变量 count 从内存加载到 CPU 的寄存器
   - 之后，在寄存器中执行 +1 操作
   - 最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）

   操作系统做任务切换，可以发生在任何一条 CPU 指令执行完。对于上面的三条指令来说，假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 A 和线程 B 按照下图的序列执行，那么我们会发现两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。

   ![非原子操作的执行路径示意图](/Picture/Java并发/极客时间-Java并发编程实战/非原子操作的执行路径示意图.png)

   **一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性**

   

4. ##### 编译优化带来的有序性问题

   编译器为了优化性能，有时候会改变程序中语句的先后顺序，在Java中解决有序性问题的一个案例是利用双重检查创建单例对象。

   `public class Singleton {
     static Singleton instance;
     static Singleton getInstance(){
       if (instance == null) {
         synchronized(Singleton.class) {
           if (instance == null)
             instance = new Singleton();
           }
       }
       return instance;
     }
   }`

   假设有两个线程 A、B 同时调用 getInstance() 方法，他们会同时发现 instance == null ，于是同时对 Singleton.class 加锁，此时 JVM 保证只有一个线程能够加锁成功（假设是线程 A），另外一个线程则会处于等待状态（假设是线程 B）；线程 A 会创建一个 Singleton 实例，之后释放锁，锁释放后，线程 B 被唤醒，线程 B 再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程 B 检查 instance == null 时会发现，已经创建过 Singleton 实例了，所以线程 B 不会再创建一个 Singleton 实例。

   实际上这个 getInstance() 方法并不完美。我们以为的 new 操作应该是：

   - 分配一块内存 M；
   - 在内存 M 上初始化 Singleton 对象；
   - 然后 M 的地址赋值给 instance 变量。

   实际上优化后的路径是

   - 分配一块内存 M；
   - 将 M 的地址赋值给 instance 变量；
   - 最后在内存 M 上初始化 Singleton 对象。

   我们假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 instance != null ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。

   ![双重检查创建单例的异常执行路径](/Picture/Java并发/极客时间-Java并发编程实战/双重检查创建单例的异常执行路径.png)
   
   

5. ##### 总结

   只要我们能够深刻理解可见性、原子性、有序性在并发场景下的原理，很多并发 Bug 都是可以理解、可以诊断的。

   介绍可见性、原子性、有序性的时候，特意提到缓存导致的可见性问题，线程切换带来的原子性问题，编译优化带来的有序性问题，其实缓存、线程、编译优化的目的和我们写并发程序的目的是相同的，都是提高程序性能。但是技术在解决一个问题的同时，必然会带来另外一个问题，所以在采用一项技术的同时，一定要清楚它带来的问题是什么，以及如何规避。



### 二、Java内存模型：看Java如何解决可见性和有序性问题

1. ##### 什么是 Java 内存模型？

   导致可见性的原因是缓存，导致有序性的原因是编译优化，解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是这样问题虽然解决了，程序的性能可就堪忧了。合理的方案是按需禁用缓存和编译优化。Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则。

   

2. ##### volatile 

   volatile 关键字并不是 Java 语言的特产，古老的 C 语言里也有，它最原始的意义就是禁用 CPU 缓存。它表达的是：告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。

   例如下面的示例代码，假设线程 A 执行 writer() 方法，按照 volatile 语义，会把变量 “v=true” 写入内存；假设线程 B 执行 reader() 方法，同样按照 volatile 语义，线程 B 会从内存中读取变量 v，如果线程 B 看到 “v == true” 时，那么线程 B 看到的变量 x 是多少呢？

   直觉上看，应该是 42，那实际应该是多少呢？这个要看 Java 的版本，如果在低于 1.5 版本上运行，x 可能是 42，也有可能是 0；如果在 1.5 以上的版本上运行，x 就是等于 42。变量 x 被 CPU 缓存而导致可见性问题。但是1.5版本后不会出现这个问题，Java 内存模型在 1.5 版本对 volatile 语义进行了增强

   `class VolatileExample {
     int x = 0;
     volatile boolean v = false;
     public void writer() {
       x = 42;
       v = true;
     }
     public void reader() {
       if (v == true) {
         // 这里x会是多少呢？
       }
     }
   }`

   

3. ##### Happens-Before 规则

   Happens-Before意思是前面一个操作的结果对后续操作是可见的。Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 Happens-Before 规则。以下6项都是关于可见性的

   1. ###### 程序的顺序性规则

      这条规则是指在一个线程中，按照程序顺序。前面的操作 Happens-Before 于后续的任意操作。比如刚才那段示例代码，按照程序的顺序，第 6 行代码 “x = 42;” Happens-Before 于第 7 行代码 “v = true;”，这就是规则 1 的内容，也比较符合单线程里面的思维：程序前面对某个变量的修改一定是对后续操作可见的。

   2. ###### volatile 变量规则

      这条规则是指对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作。对一个 volatile 变量的写操作相对于后续对这个 volatile 变量的读操作可见。

   3. ###### 传递规则

      这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。

      ![传递性](/Picture/Java并发/极客时间-Java并发编程实战/传递性.png)

      - “x=42” Happens-Before 写变量 “v=true” ，这是规则 1 的内容；
      - 写变量“v=true” Happens-Before 读变量 “v=true”，这是规则 2 的内容 。
      - 根据这个传递性规则，我们得到结果：“x=42” Happens-Before 读变量“v=true”

      这样的话，如果线程 B 读到了“v=true”，那么线程 A 设置的“x=42”对线程 B 是可见的。也就是说，线程 B 能看到 “x == 42” ，有没有一种恍然大悟的感觉？这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大，1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性。

   4. ###### 管程中锁的规则

      这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。**管程**是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。管程中的锁在 Java 里是隐式实现的，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。

      `synchronized (this) { //此处自动加锁
        // x是共享变量,初始值=10
        if (this.x < 12) {
          this.x = 12; 
        }  
      } //此处自动解锁`

      管程中锁的规则：假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。

   5. ###### 线程 start() 规则

      这条是关于线程启动的。它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。线程 A 调用线程 B 的 start() 方法（即在线程 A 中启动线程 B），那么该 start() 操作 Happens-Before 于线程 B 中的任意操作。

   6. ###### 线程 join() 规则

      这条是关于线程等待的。它是指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。“看到”，指的是对共享变量的操作。

      

4. ##### 被忽视的 final

   **final 修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化。**在 1.5 以后 Java 内存模型对 final 类型变量的重排进行了约束。现在只要我们提供正确构造函数没有“逸出”，就不会出问题了。

   在下面例子中，在构造函数里面将 this 赋值给了全局变量 global.obj，这就是“逸出”，线程通过 global.obj 读取 x 是有可能读到 0 的。因此我们一定要避免“逸出”。

   `final int x;
   // 错误的构造函数
   public FinalFieldExample() { 
     x = 3;
     y = 4;
     // 此处就是讲this逸出，
     global.obj = this;
   }`

   

5. ##### 总结

   Java 的内存模型是并发编程领域的一次重要创新。Java 内存模型里面，最晦涩的部分就是 Happens-Before 规则了，Happens-Before 规则最初是在一篇叫做 **Time, Clocks, and the Ordering of Events in a Distributed System** 的论文中提出来的，在这篇论文中，Happens-Before 的语义是一种因果关系。

   在 Java 语言里面，Happens-Before 的语义本质上是一种可见性，A Happens-Before B 意味着 A 事件对 B 事件来说是可见的，无论 A 事件和 B 事件是否发生在同一个线程里。例如 A 事件发生在线程 1 上，B 事件发生在线程 2 上，Happens-Before 规则保证线程 2 上也能看到 A 事件的发生。

   Java 内存模型主要分为两部分，一部分面向你我这种编写并发程序的应用开发人员，另一部分是面向 JVM 的实现人员的，我们可以重点关注前者，也就是和编写并发程序相关的部分，这部分内容的核心就是 Happens-Before 规则。

   **Happens-Before原则**

   - **程序次序规则**：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
   - **锁定规则**：一个unLock操作先行发生于后面对同一个锁额lock操作；
   - **volatile变量规则**：对一个变量的写操作先行发生于后面对这个变量的读操作；
   - **传递规则**：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
   - **线程启动规则**：Thread对象的start()方法先行发生于此线程的每个一个动作；
   - **线程中断规则**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
   - **线程终结规则**：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
   - **对象终结规则**：一个对象的初始化完成先行发生于他的finalize()方法的开始；



### 三、互斥锁：解决原子性问题

1. ##### 如何解决原子性问题？

   原子性问题的源头是**线程切换**，如果能够禁用线程切换那就能解决这个问题。操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。

   单核 CPU 时代，这个方案的确是可行的，long 型变量是 64 位，在 32 位 CPU 上执行写操作会被拆分成两次写操作。单核 CPU 场景下，同一时刻只有一个线程执行，禁止 CPU 中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得 CPU 使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。

   但是，多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在 CPU-1 上，一个线程执行在 CPU-2 上，此时禁止 CPU 中断，只能保证 CPU 上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写 long 型变量高 32 位。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。

   

2. ##### 简易锁模型

   我们把一段需要互斥执行的代码称为临界区。线程在进入临界区之前，首先尝试加锁 lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁 unlock()。

   ![简易锁模型](/Picture/Java并发/极客时间-Java并发编程实战/简易锁模型.png)

   

3. ##### 改进后锁模型

   锁和锁要保护的资源是有对应关系，上面的模型中是没有体现。首先我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。

   ![改进后锁模型](/Picture/Java并发/极客时间-Java并发编程实战/改进后锁模型.png)

   

4. ##### Java锁技术：synchronized

   Java 语言提供的 synchronized 关键字，就是锁的一种实现。

   `class X {
     // 修饰非静态方法
     synchronized void foo() {
       // 临界区
     }
     // 修饰静态方法
     synchronized static void bar() {
       // 临界区
     }
     // 修饰代码块
     Object obj = new Object()；
     void baz() {
       synchronized(obj) {
         // 临界区
       }
     }
   }  `

   Java 编译器会在 synchronized 修饰的方法或代码块前后自动加上加锁 lock() 和解锁 unlock()，这样做的好处就是加锁 lock() 和解锁 unlock() 一定是成对出现的.

   当修饰静态方法的时候，锁定的是当前类的 Class 对象，在上面的例子中就是 Class X；当修饰非静态方法的时候，锁定的是当前实例对象 this。

   `class X {
     // 修饰静态方法
     synchronized(X.class) static void bar() {
       // 临界区
     }
   }`

   `class X {
     // 修饰非静态方法
     synchronized(this) void foo() {
       // 临界区
     }
   }`

   **使用synchronized解决count+=1问题**

   `class SafeCalc {
     long value = 0L;
     long get() {
       return value;
     }
     synchronized void addOne() {
       value += 1;
     }
   }`

   addOne() 方法，首先可以肯定，被 synchronized 修饰后，无论是单核 CPU 还是多核 CPU，只有一个线程能够执行 addOne() 方法，所以一定能保证原子操作。

   管程，就是我们这里的 synchronized。synchronized 修饰的临界区是互斥的，也就是说同一时刻只有一个线程执行临界区的代码；而所谓“对一个锁解锁  Happens-Before 后续对这个锁的加锁”，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合 Happens-Before 的传递性原则，我们就能得出前一个线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。

   多个线程同时执行 addOne() 方法，可见性是可以保证的，也就说如果有 1000 个线程执行 addOne() 方法，最终结果一定是 value 的值增加了 1000。

   这个时候需要想一下，执行 addOne() 方法后，value 的值对 get() 方法是可见的吗？管程中锁的规则，是只保证后续对这个锁的加锁的可见性，而 get() 方法并没有加锁操作，所以可见性没法保证。get() 方法也 synchronized 一下，这样get出来的值就是同步之后的了，value的值对于get方法是可见的。

   ![保护临界区get和addOne](/Picture/Java并发/极客时间-Java并发编程实战/保护临界区get和addOne.png)

   get() 方法和 addOne() 方法都需要访问 value 这个受保护的资源，这个资源用 this 这把锁来保护。线程要进入临界区 get() 和 addOne()，必须先获得 this 这把锁，这样 get() 和 addOne() 也是互斥的。

   

5. ##### 锁和受保护资源的关系

   受保护资源和锁之间的关联关系非常重要，他们的关系是怎样的呢？合理的关系是：**受保护资源和锁之间的关联关系是 N:1 的关系，**在并发领域，我们不能用多把锁去保护一个资源，但是可以用一把锁去保护多个资源。

   上面的代码例子，把 value 改成静态变量，把 addOne() 方法改成静态方法，此时 get() 方法和 addOne() 方法是否存在并发问题呢？

   `class SafeCalc {
     static long value = 0L;
     synchronized long get() {
       return value;
     }
     synchronized static void addOne() {
       value += 1;
     }
   }`

   仔细观察，就会发现改动后的代码是用两个锁保护一个资源。这个受保护的资源就是静态变量 value，两个锁分别是 this 和 SafeCalc.class。

   由于临界区 get() 和 addOne() 是用两个锁保护的，因此这两个临界区没有互斥关系，临界区 addOne() 对 value 的修改对临界区 get() 也没有可见性保证，这就导致并发问题了。

   ![两把锁保护一个资源](/Picture/Java并发/极客时间-Java并发编程实战/两把锁保护一个资源.png)

   

6. ##### 总结

   **互斥锁**，在并发领域的知名度极高，只要有了并发问题，大家首先容易想到的就是加锁，因为大家都知道，加锁能够保证执行临界区代码的互斥性。这样理解虽然正确，但是却不能够指导真正用好互斥锁。临界区的代码是操作受保护资源的路径。所以必须深入分析锁定的对象和受保护资源的关系，综合考虑受保护资源的访问路径，多方面考量才能用好互斥锁。

   synchronized 是 Java 在语言层面提供的互斥原语，其实 Java 里面还有很多其他类型的锁，但作为互斥锁，原理都是相通的：锁，一定有一个要锁定的对象，至于这个锁定的对象要保护的资源以及在哪里加锁 / 解锁，就属于设计层面的事情了。



### 四、互斥锁：如何用一把锁保护多个资源

​	受保护资源和锁之间合理的关联关系应该是 N:1 的关系，可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源。要保护多个资源时，首先要区分这些资源是否存在关联关系。

1. ##### 保护没有关联关系的多个资源

   在银行业务中有针对账户余额的取款操作，也有针对账户密码的更改操作，可以为账户余额和账户密码分配不同的锁来解决并发问题。

   账户类 Account 有两个成员变量，分别是账户余额 balance 和账户密码 password。取款 withdraw() 和查看余额 getBalance() 操作会访问账户余额 balance，我们创建一个 final 对象 balLock 作为锁；而更改密码 updatePassword() 和查看密码 getPassword() 操作会修改账户密码 password，我们创建一个 final 对象 pwLock 作为锁。不同的资源用不同的锁保护，各自管各自的，很简单。

   `class Account {`
     `// 锁：保护账户余额`
     `private final Object balLock`
       `= new Object();`
     `// 账户余额  
     private Integer balance;`
     `// 锁：保护账户密码`
     `private final Object pwLock`
       `= new Object();`
     `// 账户密码`
     `private String password;`

     `// 取款`
     `void withdraw(Integer amt) {`
       `synchronized(balLock) {`
         `if (this.balance > amt){`
           `this.balance -= amt;`
         `}`
       `}`
     `}` 
     `// 查看余额`
     `Integer getBalance() {`
       `synchronized(balLock) {`
         `return balance;`
       `}`
     `}`

     `// 更改密码`
     `void updatePassword(String pw){`
       `synchronized(pwLock) {`
         `this.password = pw;`
       `}`
     `}` 
     `// 查看密码`
     `String getPassword() {`
       `synchronized(pwLock) {`
         `return password;`
       `}`
     `}`
   `}`

   也可以用一把互斥锁来保护多个资源，可以用 this 这一把锁来管理账户类里所有的资源：账户余额和用户密码，示例程序中所有的方法都增加同步关键字 synchronized 就可以了。但是用一把锁，性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。而用两把锁，取款和修改密码是可以并行的。**用不同的锁对受保护资源进行精细化管理，能够提升性能。**这种锁还有个名字，叫细**粒度锁**。

   

2. ##### 保护有关联关系的多个资源

   如果多个资源是有关联关系的，那这个问题就有点复杂了。Account类有一个成员变量余额：balance，还有一个用于转账的方法：transfer()，如何保证转账操作没有并发问题呢？

   `class Account {
     private int balance;
     // 转账
     void transfer(
         Account target, int amt){
       if (this.balance > amt) {
         this.balance -= amt;
         target.balance += amt;
       }
     } 
   }`

   直觉会告诉自己解决方案：用户 synchronized 关键字修饰一下 transfer() 方法就可以了

   `class Account {
     private int balance;
     // 转账
     synchronized void transfer(
         Account target, int amt){
       if (this.balance > amt) {
         this.balance -= amt;
         target.balance += amt;
       }
     } 
   }`

   但是，这样会出现问题，this 这把锁可以保护自己的余额 this.balance，却保护不了别人的余额 target.balance。

   ![用锁 this 保护 this.balance 和 target.balance](/Picture/Java并发/极客时间-Java并发编程实战/用锁 this 保护 this.balance 和 target.balance.png)

   假设有 A、B、C 三个账户，余额都是 200 元，我们用两个线程分别执行两个转账操作：账户 A 转给账户 B 100 元，账户 B 转给账户 C 100 元，最后我们期望的结果应该是账户 A 的余额是 100 元，账户 B 的余额是 200 元， 账户 C 的余额是 300 元。

   假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？我们期望是，但实际上并不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 transfer()。同时进入临界区的结果是什么呢？线程 1 和线程 2 都会读到账户 B 的余额为 200，导致最终账户 B 的余额可能是 300（线程 1 后于线程 2 写 B.balance，线程 2 写的 B.balance 值被线程 1 覆盖），可能是 100（线程 1 先于线程 2 写 B.balance，线程 1 写的 B.balance 值被线程 2 覆盖），就是不可能是 200。

   ![并发转账](/Picture/Java并发/极客时间-Java并发编程实战/并发转账.png)

   

3. ##### 使用锁的正确姿势

   如何使用同一把锁来保护多个资源，只要我们的**锁能覆盖所有受保护资源**就可以了。this 是对象级别的锁，所以 A 对象和 B 对象都有自己的锁，如何让 A 对象和 B 对象共享一把锁？

   - 让所有对象都持有一个唯一性的对象，这个对象在创建 Account 时传入。把 Account 默认构造函数变为 private，同时增加一个带 Object lock 参数的构造函数，创建 Account 对象时，传入相同的 lock，这样所有的 Account 对象都会共享这个 lock 了。它要求在创建 Account 对象的时候必须传入同一个对象，如果创建 Account 对象时，传入的 lock 不是同一个对象，那可就惨了，会出现锁自家门来保护他家资产的荒唐事。

     `class Account {
       private Object lock；
       private int balance;
       private Account();
       // 创建Account时传入同一个lock对象
       public Account(Object lock) {
         this.lock = lock;
       } 
       // 转账
       void transfer(Account target, int amt){
         // 此处检查所有对象共享的锁
         synchronized(lock) {
           if (this.balance > amt) {
             this.balance -= amt;
             target.balance += amt;
           }
         }
       }
     }`

   - 更好的方案就是用 Account.class 作为共享的锁。Account.class 是所有 Account 对象共享的，而且这个对象是 Java 虚拟机在加载 Account 类的时候创建的，所以我们不用担心它的唯一性。使用 Account.class 作为共享的锁，我们就无需在创建 Account 对象时传入了，代码更简单。

     `class Account {
       private int balance;
       // 转账
       void transfer(Account target, int amt){
         synchronized(Account.class) {
           if (this.balance > amt) {
             this.balance -= amt;
             target.balance += amt;
           }
         }
       } 
     }`

     ![使用共享锁Account.class保护不同对象的临界区](/Picture/Java并发/极客时间-Java并发编程实战/使用共享锁Account.class保护不同对象的临界区.png)

     

4. ##### 总结

   如何保护多个资源？关键是要分析多个资源之间的关系。如果资源之间没有关系，很好处理，每个资源一把锁就可以了。如果资源之间有关联关系，就要选择一个粒度更大的锁，这个锁应该能够覆盖所有相关的资源。除此之外，还要梳理出有哪些访问路径，所有的访问路径都要设置合适的锁。

   关联关系如果用更具体、更专业的语言来描述的话，其实是一种“原子性”特征。原子性，主要是面向 CPU 指令的，转账操作的原子性则是属于是面向高级语言的，不过它们本质上是一样的。

   **“原子性”的本质**是什么？其实不是不可分割，不可分割只是外在表现，其本质是多个资源间有一致性的要求，**操作的中间状态对外不可见。**例如，在 32 位的机器上写 long 型变量有中间状态（只写了 64 位中的 32 位），在银行转账的操作中也有中间状态（账户 A 减少了 100，账户 B 还没来得及发生变化）。所以**解决原子性问题，是要保证中间状态对外不可见。**



### 五、如果死锁了，应该如何做？

​	之前，我们使用Account.class 作为互斥锁，来解决银行业务里面的转账问题，虽然这个方案不存在并发问题，但是所有账户的转账操作都是串行的。但是账户 A 转账户 B、账户 C 转账户 D 这两个转账操作现实世界里是可以并行的，在这个方案里却被串行化了，这样的话，性能太差。若所有的转账操作都串行，性能完全不能接受。

1. ##### 模仿现实世界

   现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。

   没有信息化的时代，账户的存在形式是一个账本，每个账户都有一个账本，这些账本统一存放在文件架上。银行柜员在给做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个时候可能遇到以下三种情况

   - 文件架上恰好有转出账本和转入账本，那就同时拿走
   - 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来；
   - 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来。

   通过使用两把锁就可以实现，转出账本一把，转入账本另一把。在 transfer() 方法内部，首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。

   ![转账示意图](/Picture/Java并发/极客时间-Java并发编程实战/转账示意图.png)

   上面的实现看上去很完美，并且也算是将锁用得出神入化了。相对于用 Account.class 作为互斥锁，锁定的范围太大，而我们锁定两个账户范围就小多了。这种**细粒度锁。使用它可以提高并行度，是性能优化的一个重要手段。但是使用细粒度锁是有代价的，这个代价就是可能会导致死锁。**

   比如：A转账给B，B转账给A，这个时候入账出账两个账本在不同的线程上，这样是会出现死锁的，两个线程都在互相等待对方的账本，这就产生了死锁。**死锁**的一个比较专业的定义是：**一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。**

   ![转账业务中死锁等待](/Picture/Java并发/极客时间-Java并发编程实战/转账业务中死锁等待.png)

   `class Account {
     private int balance;
     // 转账
     void transfer(Account target, int amt){
       // 锁定转出账户
       synchronized(this){     ①
         // 锁定转入账户
         synchronized(target){ ②
           if (this.balance > amt) {
             this.balance -= amt;
             target.balance += amt;
           }
         }
       }
     } 
   }`

   这种现象，还可以借助资源分配图来可视化锁的占用情况（资源分配图是个有向图，它可以描述资源和线程的状态）。其中，资源用方形节点表示，线程用圆形节点表示；资源中的点指向线程的边表示线程已经获得该资源，线程指向资源的边则表示线程请求资源，但尚未得到。

   ![转账发生死锁时的资源分配图](/Picture/Java并发/极客时间-Java并发编程实战/转账发生死锁时的资源分配图.png)

   

2. ##### 如何预防死锁

   并发程序一旦死锁，一般没有特别好的方法，很多时候我们只能重启应用。因此，解决死锁问题最好的办法还是规避死锁。
   那如何避免死锁呢？要避免死锁就需要分析死锁发生的条件，以下这四个条件都发生时才会出现死锁：

   - 互斥，共享资源 X 和 Y 只能被一个线程占用；
   - 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
   - 不可抢占，其他线程不能强行抢占线程 T1 占有的资源；
   - 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。

   **也就是说只要我们破坏其中一个，就可以成功避免死锁的发生。**

   除了互斥条件，其他三个条件都是有办法破坏的。

   - 对于**“占用且等待”**这个条件，我们可以**一次性申请所有的资源，这样就不存在等待**了。

   - 对于**“不可抢占”**这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。

   - 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。

     

   1. ###### 破坏占用且等待条件

      要破坏这个条件，可以一次性申请所有资源。比如：可以增加一个账本管理员，然后只允许账本管理员从文件架上拿账本，也就是说柜员不能直接在文件架上拿账本，必须通过账本管理员才能拿到想要的账本。例如，张三同时申请账本 A 和 B，账本管理员如果发现文件架上只有账本 A，这个时候账本管理员是不会把账本 A 拿下来给张三的，只有账本 A 和 B 都在的时候才会给张三。这样就保证了“一次性申请所有资源”。

      对应到编程领域，“同时申请”这个操作是一个临界区，我们需要一个角色（Java 里面的类）来管理这个临界区，把这个角色定为 Allocator。它有两个重要功能，分别是：同时申请资源 apply() 和同时释放资源 free()。账户 Account 类里面持有一个 Allocator 的单例（必须是单例，只能由一个人来分配资源）。当账户 Account 在执行转账操作的时候，首先向 Allocator 同时申请转出账户和转入账户这两个资源，成功后再锁定这两个资源；当转账操作执行完，释放锁之后，我们需通知 Allocator 同时释放转出账户和转入账户这两个资源。

      `class Allocator {`
        `private List<Object> als = new ArrayList<>();`
        `// 一次性申请所有资源`
        `synchronized boolean apply(`
          `Object from, Object to){`
          `if(als.contains(from) ||`
               `als.contains(to)){`
            `return false;  
          } else {`
            `als.add(from);`
            `als.add(to);  
          }`
          `return true;`
        `}`
        `// 归还资源`
        `synchronized void free(`
          `Object from, Object to){`
          `als.remove(from);`
          `als.remove(to);`
        `}`
      `}`

      `class Account {`
        `// actr应该为单例`
        `private Allocator actr;`
        `private int balance;`
        `// 转账`
        `void transfer(Account target, int amt){`
          `// 一次性申请转出账户和转入账户，直到成功`
          `while(!actr.apply(this, target))`
            `；`
          `try{`
            `// 锁定转出账户`
            `synchronized(this){  
              // 锁定转入账户`
              `synchronized(target){ 
                if (this.balance > amt){`
                  `this.balance -= amt;`
                  `target.balance += amt;`
                `}`
              `}`
            `}`
          `} finally {`
            `actr.free(this, target)`
          `}`
        `}` 
      `}`

      

   2. ###### 破坏不可抢占条件

      破坏不可抢占条件核心是要能够主动释放它占有的资源，synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。虽然Java在语言层面没有解决该问题，不过在 SDK 层面还是解决了的，java.util.concurrent 这个包下面提供的 Lock 是可以轻松解决这个问题的。

      

   3. ###### 破坏循环等待条件

      破坏这个条件，需要对资源进行排序，然后按序申请资源。假设每个账户都有不同的属性 id，这个 id 可以作为排序字段，申请的时候，我们可以按照从小到大的顺序来申请。①~⑥处的代码对转出账户（this）和转入账户（target）排序，然后按照序号从小到大的顺序锁定账户。这样就不存在“循环”等待了。

      `class Account {
        private int id;
        private int balance;
        // 转账
        void transfer(Account target, int amt){
          Account left = this        ①
          Account right = target;    ②
          if (this.id > target.id) { ③
            left = target;           ④
            right = this;            ⑤
          }                          ⑥
          // 锁定序号小的账户
          synchronized(left){
            // 锁定序号大的账户
            synchronized(right){ 
              if (this.balance > amt){
                this.balance -= amt;
                target.balance += amt;
              }
            }
          }
        } 
      }`

      

3. ##### 总结

   我们在编程世界里遇到问题时，可以换个思路，向现实世界要答案，利用现实世界的模型来构思解决方案，这样往往能够让我们的方案更容易理解，也更能够看清楚问题的本质。

   本文主要讲了**用细粒度锁来锁定多个资源时，要注意死锁的问题**。这个需要我们能把它强化为一个思维定势，遇到这种场景，马上想到可能存在死锁问题。当你知道风险之后，才有机会谈如何预防和避免，因此，识别出风险很重要。预防死锁主要是破坏三个条件中的一个，在选择具体方案的时候，还需要**评估一下操作成本，从中选择一个成本最低的方案。**



### 六、用等待-通知来优化循环等待

​	在上面，我们破坏占有且等待条件的时候，如果转出账本和转入账本不满足同时在文件架时，使用死循环来循环等待。如果 apply() 操作耗时非常短，而且并发冲突量也不大时，循环上几次或者几十次就能一次性获取转出账户和转入账户了。如果 apply() 操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，这种场景下，可能要循环上万次才能获取到锁，太消耗CPU了。

​	这种场景下，最好的方案是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入**等待**状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，**通知**等待的线程重新执行。



1. ##### 类比就医流程

   一个基本的就医流程：

   - 患者先去挂号，然后到就诊门口分诊，等待叫号；
   - 当叫到自己的号时，患者就可以找大夫就诊了；
   - 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者；
   - 当患者做完检查后，拿检测报告重新分诊，等待叫号；
   - 当大夫再次叫到自己的号时，患者再去找大夫就诊。

   上述流程忽视的细节：

   - 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了。
   - 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足。
   - 患者去做检查，类似于线程进入等待状态；然后**大夫叫下一个患者，这个步骤我们在前面的等待 - 通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁。**
   - 患者做完检查，类似于线程要求的条件已经满足；**患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待 - 通知机制中也忽视了。**

   综合上述细节可以得出**一个完整的等待-通机制**：**线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁。**

   

2. ##### 使用synchronized实现等待-通知机制

    Java 语言里，等待 - 通知机制可以有多种实现方式，synchronized 配合 wait()、notify()、notifyAll() 这三个方法就能轻松实现。同一时刻，只允许一个线程进入 synchronized 保护的临界区，当有一个线程进入临界区后，其他线程就只能进入图中左边的等待队列里等待。**这个等待队列和互斥锁是一对一的关系，每个互斥锁都有自己独立的等待队列。**

   ![wait() 操作工作原理图](/Picture/Java并发/极客时间-Java并发编程实战/wait() 操作工作原理图.png)

   并发程序中，当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态，Java 对象的 wait() 方法就能够满足这种需求。调用 wait() 方法后，当前线程就会被阻塞，并且进入到右边的等待队列中，**这个等待队列也是互斥锁的等待队列**。 线程在进入等待队列的同时，**会释放持有的互斥锁**，线程释放锁后，其他线程就有机会获得锁，并进入临界区。线程要求的条件满足时，调用Java 对象的 notify() 和 notifyAll() 方法，会通知等待队列（**互斥锁的等待队列**）中的线程，告诉它**条件曾经满足过**。

   **notify() 只能保证在通知时间点，条件是满足的。**而**被通知线程的执行时间点和通知的时间点基本上不会重合**，所以当线程执行的时候，很可能条件已经不满足了。wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，可以发现 wait()、notify()、notifyAll() 都是在 synchronized{}内部被调用的。

   

3. ##### 使用资源分配器

   在这个等待 - 通知机制中，我们需要考虑以下四个要素。

   - **互斥锁**：上面提到 Allocator 需要是单例的，所以我们可以用 this 作为互斥锁。
   - **线程要求的条件**：转出账户和转入账户都没有被分配过。
   - **何时等待**：线程要求的条件不满足就等待。
   - **何时通知**：当有线程释放账户时就通知。

   利用循环条件判断，可以避免之前所说的条件曾经满足过的问题

   `class Allocator {
     private List<Object> als;
     // 一次性申请所有资源
     synchronized void apply(
       Object from, Object to){
       // 经典写法
       while(als.contains(from) ||
            als.contains(to)){
         try{
           wait();
         }catch(Exception e){
         }   
       } 
       als.add(from);
       als.add(to);  
     }
     // 归还资源
     synchronized void free(
       Object from, Object to){
       als.remove(from);
       als.remove(to);
       notifyAll();
     }
   }`

   

4. ##### 尽量使用notifyAll()

   上面的代码中使用的是notifyAll而不是notify，因为**notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。**使用 notify() 很有风险，它的风险在于可能导致某些线程永远不会被通知到。所以除非经过深思熟虑，否则尽量使用 notifyAll()。

   

5. ##### 总结

   **等待 - 通知机制是一种非常普遍的线程间协作的方式**。工作中经常看到有同学使用轮询的方式来等待某个状态。**很多情况下都可以用等待 - 通知机制来优化**。Java 语言内置的 synchronized 配合 wait()、notify()、notifyAll() 这三个方法可以快速实现这种机制，但是它们的使用看上去还是有点复杂，所以你需要**认真理解等待队列和 wait()、notify()、notifyAll() 的关系**。最好用现实世界做个类比，这样有助于你的理解。Java 语言的这种实现，背后的理论模型其实是管程，后续会深入讲解。



### 七、安全性、活跃性、以及性能问题

并发编程中我们需要注意的问题有很多，主要有三个方面，分别是：**安全性问题、活跃性问题和性能问题**

1. ##### 安全性问题

   我们经常可以听到这样的描述：方法不是线程安全的、类不是线程安全的。什么是线程安全呢？本质上是程序的正确性，正确性的含义就是程序按照我们期望的执行，不要让我们感到意外。

   如何才能写出线程安全的程序？**并发 Bug 的三个主要源头：原子性问题、可见性问题和有序性问题。**理论上线程安全的程序，就要避免出现原子性问题、可见性问题和有序性问题。

   在**存在共享数据并且该数据会发生变化，通俗地讲就是有多个线程会同时读写同一数据**的时候，我们需要分析以上三个问题。如果能够做到不共享数据或者数据状态不发生变化，就能够保证线程的安全性。但是现实生活中，必须共享会发生变化的数据，多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，不采取防护措施，那么就会导致并发 Bug，这种情况也称为**数据竞争**。

   有时还会发生**竞态条件**。竞态条件，指的是程序的执行结果依赖线程执行的顺序。在并发环境里，线程的执行顺序是不确定的，如果程序存在竞态条件问题，那就意味着程序执行的结果是不确定的，而执行结果不确定这可是个大 Bug。转账操作里面有个判断条件——转出金额不能大于账户余额，但在并发环境里面，如果不加控制，当多个线程同时对一个账号执行转出操作时，就有可能出现超额转出问题。

   在并发场景中，程序的执行依赖于某个状态变量，这个时候可能就会发生竞态条件

   `if (状态变量 满足 执行条件) {
     执行操作
   }`

   当某个线程发现状态变量满足执行条件后，开始执行操作；可是就在这个线程执行操作的时候，其他线程同时修改了状态变量，导致状态变量不满足执行条件了。当然很多场景下，这个条件不是显式的，例如前面 addOne 的例子中，set(get()+1) 这个复合操作，其实就隐式依赖 get() 的结果。

   面对数据竞争和竞态条件问题，如何保证线程的安全性，这两类问题，都可以用**互斥**这个技术方案。实现互斥的方案有很多，CPU 提供了相关的互斥指令，操作系统、编程语言也会提供相关的 API。从逻辑上来看，我们可以统一归为：**锁**。

   

2. ##### 活跃性问题

   **活跃性问题，指的是某个操作无法执行下去**，常见的“死锁”就是一种典型的活跃性问题，当然**除了死锁外，还有两种情况，分别是“活锁”和“饥饿”**，发生“死锁”后线程会互相等待，而且会一直等待下去，在技术上的表现形式是线程永久地“阻塞”。

   **有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”。**“活锁”的方案很简单，谦让时，尝试等待一个随机的时间就可以了。**“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况。**如果线程优先级“不均”，在 CPU 繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。

   解决“饥饿”问题的方案，有三种方案：一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。倒是方案二的适用场景相对来说更多一些。

   如何公平地分配资源？并发编程里，主要是使用公平锁。所谓公平锁，是一种先来后到的方案，线程的等待是有顺序的，排在等待队列前面的线程会优先获得资源。

   

3. ##### 性能问题

   使用“锁”要非常小心，但是如果小心过度，也可能出“性能问题”。“锁”的过度使用可能导致串行化的范围过大，这样就不能够发挥多线程的优势了，而我们之所以使用多线程搞并发程序，为的就是提升性能。

   所以要尽量减少串行，串行对性能的影响是怎么样的呢？阿姆达尔（Amdahl）定律，代表了处理器并行运算之后效率提升的能力，它正好可以解决这个问题，具体公式如下：

   ![阿姆达尔定律Amdahl](/Picture/Java并发/极客时间-Java并发编程实战/阿姆达尔定律Amdahl.png)

   公式里的 n 可以理解为 CPU 的核数，p 可以理解为并行百分比，那（1-p）就是串行百分比了，也就是我们假设的 5%。我们再假设 CPU 的核数（也就是 n）无穷大，那加速比 S 的极限就是 20。也就是说，如果我们的串行率是 5%，那么我们无论采用什么技术，最高也就只能提高 20 倍的性能。

   使用锁的时候一定要关注对性能的影响。 那怎么才能避免锁带来的性能问题？**Java SDK 并发包里之所以有那么多东西，有很大一部分原因就是要提升在某个特定领域的性能。**

   从方案层面，可以这样来解决这个问题：

   - 既然使用锁会带来性能问题，那最好的方案自然就是使用无锁的算法和数据结构了。在这方面有很多相关的技术，例如线程本地存储 (Thread Local Storage, TLS)、写入时复制 (Copy-on-write)、乐观锁等；Java 并发包里面的原子类也是一种无锁的数据结构；Disruptor 则是一个无锁的内存队列，性能都非常好
   - 第二，减少锁持有的时间。互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减少持有锁的时间。这个方案具体的实现技术也有很多，例如使用细粒度的锁，一个典型的例子就是 Java 并发包里的 ConcurrentHashMap，它使用了所谓分段锁的技术（这个技术后面我们会详细介绍）；还可以使用读写锁，也就是读是无锁的，只有写的时候才会互斥。

   性能方面的度量指标有很多，三个指标非常重要：**吞吐量、延迟和并发量**

   - **吞吐量**：指的是**单位时间内能处理的请求数量**。吞吐量越高，说明性能越好。
   - **延迟**：指的是**从发出请求到收到响应的时间**。延迟越小，说明性能越好。
   - **并发量**：指的是**能同时处理的请求数量**，一般来说随着并发量的增加、延迟也会增加。所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒。

   

4. ##### 总结

   并发编程是一个复杂的技术领域，微观上涉及到原子性问题、可见性问题和有序性问题，宏观则表现为安全性、活跃性以及性能问题。

   在设计并发程序的时候，主要是从宏观出发，也就是要重点关注它的安全性、活跃性以及性能。安全性方面要注意数据竞争和竞态条件，活跃性方面需要注意死锁、活锁、饥饿等问题，性能方面虽然介绍了两个方案，但是遇到具体问题，还是要具体分析，根据特定的场景选择合适的数据结构和算法。

   要解决问题，首先要把问题分析清楚，要写好并发程序，首先要了解并发程序相关的问题。

   **题目**：Java 语言提供的 Vector 是一个线程安全的容器，以下代码是否有问题？

   `void addIfNotExist(Vector v, 
       Object o){
     if(!v.contains(o)) {
       v.add(o);
     }
   }`

   会发生竞态条件问题。vector是线程安全，指的是它**方法单独执行的时候没有并发正确性问题**，并不代表把它的操作组合在一起没有问题。



### 八、管程：并发编程的万能钥匙

​	并发编程这个技术领域已经发展了半个世纪了，一种核心技术可以很方便地解决我们的并发问题，那就是管程。Java 语言在 1.5 之前，提供的唯一的并发原语就是管程，而且 1.5 之后提供的 SDK 并发包，也是以管程技术为基础的。

1. ##### 什么是管程

   Java 在 1.5 之前仅仅提供了 synchronized 关键字及 wait()、notify()、notifyAll()。在操作系统课程里告诉我们，使用信号量可以解决几乎所有的并发问题。Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。**管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。**但是管程更容易使用，所以 Java 选择了管程。

   管程对应的英文是Monitor，也称作“监视器”，操作系统领域一般翻译成“管程”。**管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。**管理类的成员变量和成员方法，让这个类是线程安全的。

   

2. ##### MESA模型

   在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。

   并发编程领域，有**两大核心问题**：一个是**互斥**，即同一时刻只允许一个线程访问共享资源；另一个是**同步**，即**线程之间如何通信、协作。这两大问题，管程都是能够解决的。**

   管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。

   ![管程模型的代码化语义](/Picture/Java并发/极客时间-Java并发编程实战/管程模型的代码化语义.png)

   管程如何解决线程间的**同步**问题呢？

   这个问题会比较复杂，不过可以借鉴一下曾经提到过的就医流程，它可以帮助你快速地理解这个问题。在下面，展示了一幅 MESA 管程模型示意图，它详细描述了 MESA 模型的主要组成部分。

   在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。

   管程里还引入了条件变量的概念，而且**每个条件变量都对应有一个等待队列**，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。

   ![MESA管程模型](/Picture/Java并发/极客时间-Java并发编程实战/MESA管程模型.png)

   条件变量和等待队列的作用是什么呢？其实就是解决线程同步问题。

   假设有个线程 T1 执行出队操作，不过需要注意的是执行出队操作，有个前提条件，就是队列不能是空的，而队列不空这个前提条件就是管程里的条件变量。 如果线程 T1 进入管程后恰好发现队列是空的，就需要等待，去哪里等呢？可以去条件变量对应的等待队列里面等。

   再假设之后另外一个线程 T2 执行入队操作，入队操作执行成功之后，“队列不空”这个条件对于线程 T1 来说已经满足了，此时线程 T2 要通知 T1，告诉它需要的条件已经满足了。当线程 T1 得到通知后，会从等待队列里面出来，但是出来之后不是马上执行，而是重新进入到入口等待队列里面。

   条件变量及其等待队列我们讲清楚了，下面再说说 wait()、notify()、notifyAll() 这三个操作。前面提到线程 T1 发现“队列不空”这个条件不满足，需要进到对应的等待队列里等待。这个过程就是通过调用 wait() 来实现的。如果我们用对象 A 代表“队列不空”这个条件，那么线程 T1 需要调用 A.wait()。同理当“队列不空”这个条件满足时，线程 T2 需要调用 A.notify() 来通知 A 等待队列中的一个线程，此时这个队列里面只有线程 T1。至于 notifyAll() 这个方法，它可以通知等待队列中的所有线程。

   下面的代码实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁，类比管程模型中的入口。

   - 对于入队操作，如果队列已满，就需要等待直到队列不满，所以这里用了notFull.await();。
   - 对于出队操作，如果队列为空，就需要等待直到队列不空，所以就用了notEmpty.await();。
   - 如果入队成功，那么队列就不空了，就需要通知条件变量：队列不空notEmpty对应的等待队列。
   - 如果出队成功，那就队列就不满了，就需要通知条件变量：队列不满notFull对应的等待队列。

   `public class BlockedQueue<T>{
     final Lock lock =
       new ReentrantLock();
     // 条件变量：队列不满  
     final Condition notFull =
       lock.newCondition();
     // 条件变量：队列不空  
     final Condition notEmpty =
       lock.newCondition();`

   `// 入队
     void enq(T x) {
       lock.lock();
       try {
         while (队列已满){
           // 等待队列不满 
           notFull.await();
         }  
         // 省略入队操作...
         //入队后,通知可出队
         notEmpty.signal();
       }finally {
         lock.unlock();
       }
     }`

   `
     // 出队
     void deq(){
       lock.lock();
       try {
         while (队列已空){
           // 等待队列不空
           notEmpty.await();
         }
         // 省略出队操作...
         //出队后，通知可入队
         notFull.signal();
       }finally {
         lock.unlock();
       }  
     }
   }`

   在这段示例代码中，用了 Java 并发包里面的 Lock 和 Condition，如果看着吃力，也没关系，后面我们还会详细介绍，这个例子只是先让你明白条件变量及其等待队列是怎么回事。需要注意的是：**await() 和前面我们提到的 wait() 语义是一样的；signal() 和前面我们提到的 notify() 语义是一样的。**

   

3. ##### wait()的正确使用

   对于 **MESA 管程来说，有一个编程范式**，就是**需要在一个 while 循环里面调用 wait()。**这个是 MESA 管程特有的。

   Hasen 模型、Hoare 模型和 MESA 模型的一个核心区别就是当条件满足后，如何通知相关线程。管程要求同一时刻只允许一个线程执行，那当线程 T2 的操作使线程 T1 等待的条件满足时，T1 和 T2 究竟谁可以执行？

   - Hasen 模型里面，要求 notify() 放在代码的最后，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。
   - Hoare 模型里面，T2 通知完 T1 后，T2 阻塞，T1 马上执行；等 T1 执行完，再唤醒 T2，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。
   - MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。

   

4. ##### 什么时候可以notify()

   之前提到过，**除非经过深思熟虑，否则尽量使用 notifyAll()。**那什么时候可以使用 notify() 呢？满足以下三个条件后即可：

   1. 所有等待线程拥有相同的等待条件；
   2. 所有等待线程被唤醒后，执行相同的操作；
   3. 只需要唤醒一个线程。

   上面阻塞队列的例子中，对于“队列不满”这个条件变量，其阻塞队列里的线程都是在等待“队列不满”这个条件，反映在代码里就是下面这 3 行代码。对所有等待线程来说，都是执行这 3 行代码，**重点是 while 里面的等待条件是完全相同的**。

   `while (队列已满){
     // 等待队列不满
     notFull.await();
   }`

   等待线程被唤醒后执行的操作也是相同的

   `// 省略入队操作...
   //入队后,通知可出队
   notEmpty.signal();`

   同时也满足第 3 条，只需要唤醒一个线程。所以上面阻塞队列的代码，使用 signal() 是可以的。

   

5. ##### 总结

   Java 参考了 MESA 模型，语言内置的管程（synchronized）对 MESA 模型进行了精简。MESA 模型中，条件变量可以有多个，Java 语言内置的管程里只有一个条件变量。具体如下图所示。

   ![Java 中的管程示意图](/Picture/Java并发/极客时间-Java并发编程实战/Java 中的管程示意图.png)

   Java 内置的管程方案（synchronized）使用简单，synchronized 关键字修饰的代码块，在编译期会自动生成相关加锁和解锁的代码，但是仅支持一个条件变量；而 Java SDK 并发包实现的管程支持多个条件变量，不过并发包里的锁，需要开发人员自己进行加锁和解锁操作。

   并发编程里两大核心问题——互斥和同步，都可以由管程来帮你解决。学好管程，理论上所有的并发问题你都可以解决，并且很多并发工具类底层都是管程实现的，所以学好管程，就是相当于掌握了一把并发编程的万能钥匙。

































### 参考列表

1. [极客时间---Java并发编程实战](https://time.geekbang.org/column/intro/100023901)

